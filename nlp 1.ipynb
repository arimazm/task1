{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection', encoding = 'latin_1', sep='\\t', header = None)\n",
    "df.columns = ['label', 'message']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spams = {'spam': 1, 'ham': 0}\n",
    "df['spam'] = df['label'].map(spams).astype(int) # changed to make further calculations easier\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=pd.value_counts(df[\"label\"], sort= True)\n",
    "classes.plot(kind= 'bar', color= [\"blue\", \"red\"])\n",
    "plt.title('Distribution of classes')\n",
    "plt.show() # to see the distribution of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "1. turn everything to lowercase so as not to interpret upper- and lowercase words differently;\n",
    "2. bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].str.lower() # make everything lowercase so it's not case sensitive\n",
    "df['message'] = df['message'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation))) \n",
    "# got rid of punctuation\n",
    "df['message'] = df['message'].apply(nltk.word_tokenize) # made tokens\n",
    "stemmer = PorterStemmer()\n",
    "df['message'] = df['message'].apply((lambda x: [stemmer.stem(words) for words in x])) #stemmed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazi, avail, onli,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, earli, hor, u, c, alreadi, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, dont, think, he, goe, to, usf, he, li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  spam\n",
       "0   ham  [go, until, jurong, point, crazi, avail, onli,...     0\n",
       "1   ham                       [ok, lar, joke, wif, u, oni]     0\n",
       "2  spam  [free, entri, in, 2, a, wkli, comp, to, win, f...     1\n",
       "3   ham  [u, dun, say, so, earli, hor, u, c, alreadi, t...     0\n",
       "4   ham  [nah, i, dont, think, he, goe, to, usf, he, li...     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data): #bag of words function\n",
    "    \n",
    "    frequency = []\n",
    "    for i in data:\n",
    "        frequency.append(dict(Counter(i)))\n",
    "    \n",
    "    all_words = list(set([j for i in data for j in i]))\n",
    "    \n",
    "    for doc in frequency:\n",
    "        for word in all_words:\n",
    "            if word not in list(doc.keys()):\n",
    "                doc[word] = 0\n",
    "    \n",
    "    vocab = pd.DataFrame(frequency)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bag_of_words(df['message']) #applied the BOW function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go</th>\n",
       "      <th>until</th>\n",
       "      <th>jurong</th>\n",
       "      <th>point</th>\n",
       "      <th>crazi</th>\n",
       "      <th>avail</th>\n",
       "      <th>onli</th>\n",
       "      <th>in</th>\n",
       "      <th>bugi</th>\n",
       "      <th>n</th>\n",
       "      <th>...</th>\n",
       "      <th>ago</th>\n",
       "      <th>enter</th>\n",
       "      <th>excit</th>\n",
       "      <th>qi</th>\n",
       "      <th>lab</th>\n",
       "      <th>wtf</th>\n",
       "      <th>compliment</th>\n",
       "      <th>5wkg</th>\n",
       "      <th>wordnot</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      go  until  jurong  point  crazi  avail  onli  in  bugi  n  ...  ago  \\\n",
       "0      1      1       1      1      1      1     1   1     1  1  ...    0   \n",
       "1      0      0       0      0      0      0     0   0     0  0  ...    0   \n",
       "2      0      0       0      0      0      0     0   1     0  0  ...    0   \n",
       "3      0      0       0      0      0      0     0   0     0  0  ...    0   \n",
       "4      0      0       0      0      0      0     0   0     0  0  ...    0   \n",
       "...   ..    ...     ...    ...    ...    ...   ...  ..   ... ..  ...  ...   \n",
       "5567   0      0       0      0      0      0     1   0     0  0  ...    0   \n",
       "5568   1      0       0      0      0      0     0   0     0  0  ...    0   \n",
       "5569   0      0       0      0      0      0     0   1     0  0  ...    0   \n",
       "5570   0      0       0      0      0      0     0   1     0  0  ...    0   \n",
       "5571   0      0       0      0      0      0     0   0     0  0  ...    0   \n",
       "\n",
       "      enter  excit  qi  lab  wtf  compliment  5wkg  wordnot  label  \n",
       "0         0      0   0    0    0           0     0        0      0  \n",
       "1         0      0   0    0    0           0     0        0      0  \n",
       "2         0      0   0    0    0           0     0        0      1  \n",
       "3         0      0   0    0    0           0     0        0      0  \n",
       "4         0      0   0    0    0           0     0        0      0  \n",
       "...     ...    ...  ..  ...  ...         ...   ...      ...    ...  \n",
       "5567      0      0   0    0    0           0     0        0      1  \n",
       "5568      0      0   0    0    0           0     0        0      0  \n",
       "5569      0      0   0    0    0           0     0        0      0  \n",
       "5570      0      0   0    0    0           0     0        0      0  \n",
       "5571      0      0   0    0    0           0     0        0      0  \n",
       "\n",
       "[5572 rows x 8289 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['label'] = df['spam'] # added labels for further calculations\n",
    "vocab # actual bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_words = 8288 #total number of words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go</th>\n",
       "      <th>until</th>\n",
       "      <th>jurong</th>\n",
       "      <th>point</th>\n",
       "      <th>crazi</th>\n",
       "      <th>avail</th>\n",
       "      <th>onli</th>\n",
       "      <th>in</th>\n",
       "      <th>bugi</th>\n",
       "      <th>n</th>\n",
       "      <th>...</th>\n",
       "      <th>presley</th>\n",
       "      <th>ago</th>\n",
       "      <th>enter</th>\n",
       "      <th>excit</th>\n",
       "      <th>qi</th>\n",
       "      <th>lab</th>\n",
       "      <th>wtf</th>\n",
       "      <th>compliment</th>\n",
       "      <th>5wkg</th>\n",
       "      <th>wordnot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>...</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>...</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         go  until  jurong  point  crazi  avail  onli    in  bugi     n  ...  \\\n",
       "label                                                                    ...   \n",
       "0      4825   4825    4825   4825   4825   4825  4825  4825  4825  4825  ...   \n",
       "1       747    747     747    747    747    747   747   747   747   747  ...   \n",
       "\n",
       "       presley   ago  enter  excit    qi   lab   wtf  compliment  5wkg  \\\n",
       "label                                                                    \n",
       "0         4825  4825   4825   4825  4825  4825  4825        4825  4825   \n",
       "1          747   747    747    747   747   747   747         747   747   \n",
       "\n",
       "       wordnot  \n",
       "label           \n",
       "0         4825  \n",
       "1          747  \n",
       "\n",
       "[2 rows x 8288 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = vocab.groupby(by='label', axis=0) # to see how many messages each class has\n",
    "counts = labels.count() #each class example\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = 4825\n",
    "spam = 747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go</th>\n",
       "      <th>until</th>\n",
       "      <th>jurong</th>\n",
       "      <th>point</th>\n",
       "      <th>crazi</th>\n",
       "      <th>avail</th>\n",
       "      <th>onli</th>\n",
       "      <th>in</th>\n",
       "      <th>bugi</th>\n",
       "      <th>n</th>\n",
       "      <th>...</th>\n",
       "      <th>presley</th>\n",
       "      <th>ago</th>\n",
       "      <th>enter</th>\n",
       "      <th>excit</th>\n",
       "      <th>qi</th>\n",
       "      <th>lab</th>\n",
       "      <th>wtf</th>\n",
       "      <th>compliment</th>\n",
       "      <th>5wkg</th>\n",
       "      <th>wordnot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>417</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "      <td>815</td>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        go  until  jurong  point  crazi  avail  onli   in  bugi    n  ...  \\\n",
       "label                                                                 ...   \n",
       "0      417     22       1     17     10     13   132  815     7  137  ...   \n",
       "1       35      5       0     16      5      3    79   73     0    9  ...   \n",
       "\n",
       "       presley  ago  enter  excit  qi  lab  wtf  compliment  5wkg  wordnot  \n",
       "label                                                                       \n",
       "0            0   12      9      3   1    4    4           1     1        1  \n",
       "1            1    0     16      4   0    0    0           0     0        0  \n",
       "\n",
       "[2 rows x 8288 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words_class = labels.sum() #how often each word is met in a class\n",
    "count_words_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.866, 0.134)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find p(class)\n",
    "p_ham = ham / (ham + spam)\n",
    "p_spam = spam / (ham + spam)\n",
    "prob_class = {'ham': p_ham,\n",
    "             'spam': p_spam}\n",
    "class0 = round(prob_class['ham'], 3)\n",
    "class1 = round(prob_class['spam'], 3)\n",
    "class0, class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17649, 68143)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_num = count_words_class.sum(axis = 1)\n",
    "Nspam = words_num[1]\n",
    "Nham = words_num[0]\n",
    "Nspam, Nham # number of words in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1 # for laplacian smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_w_spam(word): # calculate likelihood of the word in SPAM class\n",
    "    if word in vocab.columns:\n",
    "        return (vocab.loc[vocab['label'] == 1, word].sum() + alpha) / (Nspam + alpha*total_words)\n",
    "    else:\n",
    "        return 1\n",
    "      \n",
    "def p_w_ham(word): # calculate likelihood of the word in HAM class\n",
    "    if word in vocab.columns:\n",
    "        return (vocab.loc[vocab['label'] == 0, word].sum() + alpha) / (Nham + alpha*total_words)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message): # final function to classify\n",
    "    p_spam_given_message = class1 # this is for the p(c) to make multiplication easier\n",
    "    p_ham_given_message = class0\n",
    "    for word in message:\n",
    "        p_spam_given_message *= p_w_spam(word) #actual calculation of p(c/w)\n",
    "        p_ham_given_message *= p_w_ham(word)\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 0\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 # settled on 0 because the probability of class 0 is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 123) # for kfold\n",
    "result = list(kf.split(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 5568, 5569, 5570]),\n",
       " array([  10,   15,   25, ..., 5565, 5567, 5571]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test and training data for 5 fold validation\n",
    "train1 = df.iloc[result[0][0]]\n",
    "test1 =  df.iloc[result[0][1]]\n",
    "\n",
    "train2 = df.iloc[result[1][0]]\n",
    "test2 =  df.iloc[result[1][1]]\n",
    "\n",
    "train3 = df.iloc[result[2][0]]\n",
    "test3 =  df.iloc[result[2][1]]\n",
    "\n",
    "train4 = df.iloc[result[3][0]]\n",
    "test4 =  df.iloc[result[3][1]]\n",
    "\n",
    "train5 = df.iloc[result[4][0]]\n",
    "test5 =  df.iloc[result[4][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train1['predicted'] = train1['message'].apply(classify)\n",
    "test1['predicted'] = test1['message'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train2['predicted'] = train2['message'].apply(classify)\n",
    "test2['predicted'] = test2['message'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train3['predicted'] = train3['message'].apply(classify)\n",
    "test3['predicted'] = test3['message'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train4['predicted'] = train4['message'].apply(classify)\n",
    "test4['predicted'] = test4['message'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/useruser/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train5['predicted'] = train5['message'].apply(classify)\n",
    "test5['predicted'] = test5['message'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9767441860465117"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 scores for each fold, then I just choose the highest value\n",
    "f1 = f1_score(test1['spam'], test1['predicted'])\n",
    "f2 = f1_score(test2['spam'], test2['predicted'])\n",
    "f3 = f1_score(test3['spam'], test3['predicted'])\n",
    "f4 = f1_score(test4['spam'], test4['predicted'])\n",
    "f5 = f1_score(test5['spam'], test5['predicted'])\n",
    "final_score = np.max([f1, f2, f3, f4, f5])\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the scikit\n",
    "df1 = pd.read_csv('SMSSpamCollection', encoding = 'latin_1', sep='\\t', header = None)\n",
    "df1.columns = ['label', 'message']\n",
    "spams = {'spam': 1, 'ham': 0}\n",
    "df1['spam'] = df1['label'].map(spams).astype(int)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1['message']\n",
    "y = df1['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= CV()\n",
    "training_data = vectorizer.fit_transform(X_train.values)\n",
    "test_data = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.9494949494949494\n"
     ]
    }
   ],
   "source": [
    "print('F1-score: {}'.format(f1_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for scikit classifier is: 0.9494949494949494\n",
      "F1-score for hands-on classifier is: 0.9767441860465117\n"
     ]
    }
   ],
   "source": [
    "print('F1-score for scikit classifier is: {}'.format(f1_score(y_test, predictions)))\n",
    "print('F1-score for hands-on classifier is: {}'.format(final_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use F1-score because it's cosidered the best representation of accuracy in this type of problems, as it considers both Precision and Recal, plus, it's best for uneven distribution, which we obviously have in this dataset. \n",
    "\n",
    "My F1-score turned out to be higher, probably because our BOWs turned out to be a bit different."
    "\n",
    "Sources: https://github.com/Midvel/medium_jupyter_notes/blob/master/naive_bayes_filter/bayes-classificator.ipynb,"
    "\n",
    "https://github.com/q-viper/ML-from-Basics/blob/master/NLP%20Bayesian%20Scratch.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
